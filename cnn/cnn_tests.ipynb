{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\TimothyKoei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\TimothyKoei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\TimothyKoei\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv1D, MaxPooling1D, Embedding, Dropout, AveragePooling1D, BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1861</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1860</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>For datasets with multiple human annotations (...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                1861        1861\n",
       "unique                                               1860           3\n",
       "top     For datasets with multiple human annotations (...  background\n",
       "freq                                                    2         997"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('../train.jsonl', lines=True)\n",
    "X_train = train_df['string']\n",
    "y_train = train_df['label']\n",
    "\n",
    "dev_df = pd.read_json('../dev.jsonl', lines=True)\n",
    "X_dev = dev_df['string']\n",
    "y_dev = dev_df['label']\n",
    "\n",
    "test_df = pd.read_json('../test.jsonl', lines=True)\n",
    "test_df = test_df[['string', 'label']]\n",
    "X_test = test_df['string']\n",
    "y_test = test_df['label']\n",
    "\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"scicite_cnn.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = text.lower()\n",
    "    text = ' '.join(x for x in text.split() if x not in stop_words)\n",
    "    return text\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = []\n",
    "    for x in text.split():\n",
    "        x = lemmatizer.lemmatize(x)\n",
    "        words.append(x)\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "def preprocessing(text):\n",
    "    # Tokenization\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "    text = cleaning(text)\n",
    "    text = lemmatize(text)\n",
    "    text = ' '.join(tokenizer.tokenize(text))\n",
    "    return text\n",
    "\n",
    "def augment_data_multiclass(X, y):\n",
    "    df = pd.concat([X, y], axis=1)\n",
    "    majority_class_size = df['label'].value_counts().max()\n",
    "    upsampled_dataframes = []\n",
    "    for class_label in df['label'].unique():\n",
    "        class_df = df[df['label'] == class_label]\n",
    "        if len(class_df) < majority_class_size:\n",
    "            class_df_upsampled = resample(class_df, replace=True, n_samples=majority_class_size, random_state=10)\n",
    "            upsampled_dataframes.append(class_df_upsampled)\n",
    "        else:\n",
    "            upsampled_dataframes.append(class_df)\n",
    "    upsampled_df = pd.concat(upsampled_dataframes)\n",
    "    return upsampled_df['string'], upsampled_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = augment_data_multiclass(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = X_train.apply(lambda x: preprocessing(x))\n",
    "X_dev_preprocessed = X_dev.apply(lambda x: preprocessing(x))\n",
    "X_test_preprocessed = X_test.apply(lambda x: preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 5000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.texts_to_sequences(X_train_preprocessed)\n",
    "X_dev_tokenized = tokenizer.texts_to_sequences(X_dev_preprocessed)\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 250\n",
    "X_train_padded = sequence.pad_sequences(X_train_tokenized, maxlen=max_words, padding='pre')\n",
    "X_dev_padded = sequence.pad_sequences(X_dev_tokenized, maxlen=max_words, padding='pre')\n",
    "X_test_padded = sequence.pad_sequences(X_test_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform string column\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_dev = label_encoder.transform(y_dev)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Category: Short data\n",
    "\n",
    "Define short data as text with number of words <= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_df = test_df[test_df['string'].apply(lambda x: len(nltk.word_tokenize(x)) <= 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>262</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>262</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>After secondary review, 93 studies were includ...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                 262         262\n",
       "unique                                                262           3\n",
       "top     After secondary review, 93 studies were includ...  background\n",
       "freq                                                    1         146"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short = short_df['string']\n",
    "y_short = short_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_preprocessed = X_short.apply(lambda x: preprocessing(x))\n",
    "X_short_tokenized = tokenizer.texts_to_sequences(X_short_preprocessed)\n",
    "X_short_padded = sequence.pad_sequences(X_short_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_short = label_encoder.transform(y_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\TimothyKoei\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\TimothyKoei\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "9/9 [==============================] - 1s 7ms/step - loss: -1031.3250 - accuracy: 0.6794 - f1: 0.6636\n"
     ]
    }
   ],
   "source": [
    "short_scores = model.evaluate(X_short_padded, y_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Category: Long data\n",
    "\n",
    "Define long data as text with number of words > 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = test_df[test_df['string'].apply(lambda x: len(nltk.word_tokenize(x)) > 25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>For datasets with multiple human annotations (...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                1599        1599\n",
       "unique                                               1598           3\n",
       "top     For datasets with multiple human annotations (...  background\n",
       "freq                                                    2         851"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_long = long_df['string']\n",
    "y_long = long_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_long_preprocessed = X_long.apply(lambda x: preprocessing(x))\n",
    "X_long_tokenized = tokenizer.texts_to_sequences(X_long_preprocessed)\n",
    "X_long_padded = sequence.pad_sequences(X_long_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_long = label_encoder.transform(y_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/step - loss: -960.7871 - accuracy: 0.6429 - f1: 0.7118\n"
     ]
    }
   ],
   "source": [
    "long_scores = model.evaluate(X_long_padded, y_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3rd Category: Paragraph data\n",
    "\n",
    "Define paragraph data as text with number of sentences > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_df = test_df[test_df['string'].apply(lambda x: len(nltk.sent_tokenize(x)) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>413</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>413</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Organotypic hippocampal slice cultures\\nInterf...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                 413         413\n",
       "unique                                                413           3\n",
       "top     Organotypic hippocampal slice cultures\\nInterf...  background\n",
       "freq                                                    1         209"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paragraph = paragraph_df['string']\n",
    "y_paragraph = paragraph_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paragraph_preprocessed = X_paragraph.apply(lambda x: preprocessing(x))\n",
    "X_paragraph_tokenized = tokenizer.texts_to_sequences(X_paragraph_preprocessed)\n",
    "X_paragraph_padded = sequence.pad_sequences(X_paragraph_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_paragraph = label_encoder.transform(y_paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: -1148.2252 - accuracy: 0.6416 - f1: 0.7513\n"
     ]
    }
   ],
   "source": [
    "paragraph_scores = model.evaluate(X_paragraph_padded, y_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4th Category: Typo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_letter(word):\n",
    "    word_list = list(word)\n",
    "    n = len(word_list)\n",
    "    if n == 1:\n",
    "        return ''.join(word_list)\n",
    "    \n",
    "    idx = random.randint(0, n - 2)\n",
    "    word_list[idx], word_list[idx + 1] = word_list[idx + 1], word_list[idx]\n",
    "    return ''.join(word_list)\n",
    "\n",
    "def rearrange_word(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    num_words = len(words)\n",
    "\n",
    "    # rearrange letter for some random word\n",
    "    for _ in range(5):\n",
    "        idx = random.randint(0, num_words - 1)\n",
    "        words[idx] = rearrange_letter(words[idx])\n",
    "    \n",
    "    # rearrange word\n",
    "    for _ in range(min(3, num_words - 1)):\n",
    "        idx = random.randint(0, num_words - 2)\n",
    "        words[idx], words[idx + 1] = words[idx + 1], words[idx]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "typo_series = test_df['string'].apply(rearrange_word)\n",
    "\n",
    "typo_df = pd.DataFrame({\n",
    "    'label': test_df.label,\n",
    "    'string': typo_series\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1861</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>background</td>\n",
       "      <td>Chapel , as well as X10 [ 2 ] , UCP [ 3 ] , Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                             string\n",
       "count         1861                                               1861\n",
       "unique           3                                               1861\n",
       "top     background  Chapel , as well as X10 [ 2 ] , UCP [ 3 ] , Co...\n",
       "freq           997                                                  1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typo_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_typo = typo_df['string']\n",
    "y_typo = typo_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_typo_preprocessed = X_typo.apply(lambda x: preprocessing(x))\n",
    "X_typo_tokenized = tokenizer.texts_to_sequences(X_typo_preprocessed)\n",
    "X_typo_padded = sequence.pad_sequences(X_typo_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_typo = label_encoder.transform(y_typo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 6ms/step - loss: -838.9789 - accuracy: 0.6411 - f1: 0.6735\n"
     ]
    }
   ],
   "source": [
    "typo_scores = model.evaluate(X_typo_padded, y_typo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5th Category: Synonym data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, iterate through the words and convert it to its synonym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1861</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1857</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>For datasets with multiple human annotation (i...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                1861        1861\n",
       "unique                                               1857           3\n",
       "top     For datasets with multiple human annotation (i...  background\n",
       "freq                                                    2         997"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymized_df = pd.read_json('../synonymized.jsonl', lines=True)\n",
    "synonymized_df = synonymized_df[['string', 'label']]\n",
    "\n",
    "synonymized_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synonymized = synonymized_df['string']\n",
    "y_synonymized = synonymized_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_synonymized_preprocessed = X_synonymized.apply(lambda x: preprocessing(x))\n",
    "X_synonymized_tokenized = tokenizer.texts_to_sequences(X_synonymized_preprocessed)\n",
    "X_synonymized_padded = sequence.pad_sequences(X_synonymized_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_synonymized = label_encoder.transform(y_synonymized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 5ms/step - loss: -196.3671 - accuracy: 0.5852 - f1: 0.4660\n"
     ]
    }
   ],
   "source": [
    "synonymized_scores = model.evaluate(X_synonymized_padded, y_synonymized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6th Category: Paraphrased data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1861</td>\n",
       "      <td>1861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1861</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Chapel, X10, UPC, CoArray Fortran, and Titaniu...</td>\n",
       "      <td>background</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   string       label\n",
       "count                                                1861        1861\n",
       "unique                                               1861           3\n",
       "top     Chapel, X10, UPC, CoArray Fortran, and Titaniu...  background\n",
       "freq                                                    1         997"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrased_test_df = pd.read_json('../paraphrased.jsonl', lines=True)\n",
    "paraphrased_test_df = paraphrased_test_df[['string', 'label']]\n",
    "\n",
    "paraphrased_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paraphrased = paraphrased_test_df['string']\n",
    "y_paraphrased = paraphrased_test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paraphrased_preprocessed = X_paraphrased.apply(lambda x: preprocessing(x))\n",
    "X_paraphrased_tokenized = tokenizer.texts_to_sequences(X_paraphrased_preprocessed)\n",
    "X_paraphrased_padded = sequence.pad_sequences(X_paraphrased_tokenized, maxlen=max_words, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_paraphrased = label_encoder.transform(y_paraphrased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 6ms/step - loss: -658.3427 - accuracy: 0.6314 - f1: 0.6906\n"
     ]
    }
   ],
   "source": [
    "paraphrased_scores = model.evaluate(X_paraphrased_padded, y_paraphrased)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Scores on Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Short</td>\n",
       "      <td>0.679389</td>\n",
       "      <td>0.663622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long</td>\n",
       "      <td>0.642902</td>\n",
       "      <td>0.711767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paragraph</td>\n",
       "      <td>0.641647</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Typo</td>\n",
       "      <td>0.641053</td>\n",
       "      <td>0.673452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synoymized</td>\n",
       "      <td>0.585169</td>\n",
       "      <td>0.465973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paraphrased</td>\n",
       "      <td>0.631381</td>\n",
       "      <td>0.690572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category  Accuracy        F1\n",
       "0        Short  0.679389  0.663622\n",
       "1         Long  0.642902  0.711767\n",
       "2    Paragraph  0.641647  0.751323\n",
       "3         Typo  0.641053  0.673452\n",
       "4   Synoymized  0.585169  0.465973\n",
       "5  Paraphrased  0.631381  0.690572"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [\"Short\", short_scores[1], short_scores[2]]\n",
    "list2 = [\"Long\", long_scores[1], long_scores[2]]\n",
    "list3 = [\"Paragraph\", paragraph_scores[1], paragraph_scores[2]]\n",
    "list4 = [\"Typo\", typo_scores[1], typo_scores[2]]\n",
    "list5 = [\"Synoymized\", synonymized_scores[1], synonymized_scores[2]]\n",
    "list6 = [\"Paraphrased\", paraphrased_scores[1], paraphrased_scores[2]]\n",
    "\n",
    "df = pd.DataFrame([list1, list2, list3, list4, list5, list6], columns=['Category', 'Accuracy', 'F1'])\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
