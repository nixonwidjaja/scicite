{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8038802,"sourceType":"datasetVersion","datasetId":4739305},{"sourceId":8115147,"sourceType":"datasetVersion","datasetId":4794341}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T09:52:04.268444Z","iopub.execute_input":"2024-04-14T09:52:04.268787Z","iopub.status.idle":"2024-04-14T09:52:05.220980Z","shell.execute_reply.started":"2024-04-14T09:52:04.268751Z","shell.execute_reply":"2024-04-14T09:52:05.220056Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/scicite/test.jsonl\n/kaggle/input/scicite/train.jsonl\n/kaggle/input/scicite2/synonymized.jsonl\n/kaggle/input/scicite2/paraphrased.jsonl\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_json('/kaggle/input/scicite/train.jsonl', lines=True)\nX_train = train_df['string']\ny_train = train_df['label']\n\ntest_df = pd.read_json('/kaggle/input/scicite/test.jsonl', lines=True)\nX_test = test_df['string']\ny_test = test_df['label']\n\nprint(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:05.222678Z","iopub.execute_input":"2024-04-14T09:52:05.223150Z","iopub.status.idle":"2024-04-14T09:52:05.485679Z","shell.execute_reply.started":"2024-04-14T09:52:05.223113Z","shell.execute_reply":"2024-04-14T09:52:05.484777Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(8243, 15) (1861, 14)\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:05.486660Z","iopub.execute_input":"2024-04-14T09:52:05.486924Z","iopub.status.idle":"2024-04-14T09:52:05.492774Z","shell.execute_reply.started":"2024-04-14T09:52:05.486901Z","shell.execute_reply":"2024-04-14T09:52:05.491713Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch \nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom torch.optim import Adam\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.utils import resample\n\ndef augment_data_multiclass(X, y):\n    df = pd.concat([X, y], axis=1)\n    majority_class_size = df['label'].value_counts().max()\n    upsampled_dataframes = []\n    for class_label in df['label'].unique():\n        class_df = df[df['label'] == class_label]\n        if len(class_df) < majority_class_size:\n            class_df_upsampled = resample(class_df, replace=True, n_samples=majority_class_size, random_state=10)\n            upsampled_dataframes.append(class_df_upsampled)\n        else:\n            upsampled_dataframes.append(class_df)\n    upsampled_df = pd.concat(upsampled_dataframes)\n    return upsampled_df['string'], upsampled_df['label']\n\n# train the model for a given number of epochs\ndef train_model(model, tokenizer, num_epoch, learning_rate, batch_size, X_train, y_train):\n    # Encode the training data\n    encoded_data_train = tokenizer.batch_encode_plus(\n        X_train,\n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n    labels_train = torch.tensor(y_train)\n\n    # Create data loader for training\n    dataset_train = TensorDataset(encoded_data_train['input_ids'], encoded_data_train['attention_mask'], labels_train)\n    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n\n    # Connect to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    # Define optimizer for training data\n    optimizer = Adam(model.parameters(), lr=learning_rate)\n\n    # Training loop\n    for epoch in range(num_epoch):\n        model.train()\n\n        curr_total_loss = 0.\n        count = 0\n        \n        for train_batch in dataloader_train:\n            optimizer.zero_grad()\n\n            id, mask, label = train_batch\n            id = id.to(device)\n            mask = mask.to(device)\n            label = label.to(device)\n\n            outputs = model(id, attention_mask=mask, labels=label)\n\n            loss = outputs.loss\n\n            curr_total_loss += loss.item()\n            count += 1\n\n            loss.backward()\n            \n            optimizer.step()\n\n        avg_loss = curr_total_loss / count\n        print(epoch, avg_loss)       \n    \n    return model \n\n# return f1 macro and accuracy of the model\ndef eval_model(model, tokenizer, X_test, y_test):\n    encoded_data_test = tokenizer.batch_encode_plus(\n        X_test,\n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n    labels_test = torch.tensor(y_test)\n\n    # Create data loader for test data\n    batch_size = 16\n    test_dataset = TensorDataset(encoded_data_test['input_ids'], encoded_data_test['attention_mask'], labels_test)\n    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n\n    # Connect to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    # Evaluate the model\n    model.eval()\n    predictions = []\n    labels = []\n    with torch.no_grad():\n        for test_batch in test_dataloader:\n            id, mask, label = test_batch\n            id = id.to(device)\n            mask = mask.to(device)\n            label = label.to(device)\n\n            outputs = model(id, attention_mask=mask, labels=label)\n            logits = outputs.logits\n            _, prediction  = torch.max(logits, dim=1)\n\n            predictions.extend(prediction.tolist())\n            labels.extend(label.tolist())\n            \n    f1 = f1_score(labels, predictions, average='macro')\n    acc = accuracy_score(labels, predictions)\n    print(f\"f1 = {f1}, accuracy = {acc}\")\n    return f1, acc\n\n\ndef save_model(model, save_path):\n    torch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:05.495484Z","iopub.execute_input":"2024-04-14T09:52:05.495836Z","iopub.status.idle":"2024-04-14T09:52:10.138024Z","shell.execute_reply.started":"2024-04-14T09:52:05.495804Z","shell.execute_reply":"2024-04-14T09:52:10.137090Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = augment_data_multiclass(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:10.139573Z","iopub.execute_input":"2024-04-14T09:52:10.140092Z","iopub.status.idle":"2024-04-14T09:52:10.164887Z","shell.execute_reply.started":"2024-04-14T09:52:10.140058Z","shell.execute_reply":"2024-04-14T09:52:10.164028Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit label encoder and transform string column\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:10.166243Z","iopub.execute_input":"2024-04-14T09:52:10.166581Z","iopub.status.idle":"2024-04-14T09:52:10.176134Z","shell.execute_reply.started":"2024-04-14T09:52:10.166551Z","shell.execute_reply":"2024-04-14T09:52:10.175266Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\nmodel_name = 'distilbert-base-uncased'\ntokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\nmodel = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\nmodel = train_model(model, tokenizer, 1, 4e-5, 16, X_train.to_list(), y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:52:10.177674Z","iopub.execute_input":"2024-04-14T09:52:10.178069Z","iopub.status.idle":"2024-04-14T09:58:58.952817Z","shell.execute_reply.started":"2024-04-14T09:52:10.178044Z","shell.execute_reply":"2024-04-14T09:58:58.951779Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7edfdbcb8ac641038d1d6a5fe1877e4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8715fe23ba4d4538ac3ae7dbd50058ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9d5f8c661714e9a9eac8e5734bc02e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9af7940f62a14ad78cae1fa5649746ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"986664e7403c4dbba88d4d0ed880e1c6"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"0 0.35008041922511773\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Test Data Evaluation**","metadata":{}},{"cell_type":"code","source":"eval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:58:58.953830Z","iopub.execute_input":"2024-04-14T09:58:58.954304Z","iopub.status.idle":"2024-04-14T09:59:16.790821Z","shell.execute_reply.started":"2024-04-14T09:58:58.954277Z","shell.execute_reply":"2024-04-14T09:59:16.789807Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"f1 = 0.8377816857463104, accuracy = 0.8527673293927995\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(0.8377816857463104, 0.8527673293927995)"},"metadata":{}}]},{"cell_type":"markdown","source":"**1st Category: Short data**","metadata":{}},{"cell_type":"code","source":"import nltk\nshort_df = test_df[test_df['string'].apply(lambda x: len(nltk.word_tokenize(x)) <= 25)]\nX_test = short_df['string']\ny_test = label_encoder.transform(short_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:03:10.890605Z","iopub.execute_input":"2024-04-14T10:03:10.890993Z","iopub.status.idle":"2024-04-14T10:03:14.167277Z","shell.execute_reply.started":"2024-04-14T10:03:10.890961Z","shell.execute_reply":"2024-04-14T10:03:14.166270Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"f1 = 0.8525919659266608, accuracy = 0.8587786259541985\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(0.8525919659266608, 0.8587786259541985)"},"metadata":{}}]},{"cell_type":"markdown","source":"**2nd Category: Long data**","metadata":{}},{"cell_type":"code","source":"long_df = test_df[test_df['string'].apply(lambda x: len(nltk.word_tokenize(x)) > 25)]\nX_test = long_df['string']\ny_test = label_encoder.transform(long_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:04:04.262303Z","iopub.execute_input":"2024-04-14T10:04:04.262985Z","iopub.status.idle":"2024-04-14T10:04:19.945618Z","shell.execute_reply.started":"2024-04-14T10:04:04.262947Z","shell.execute_reply":"2024-04-14T10:04:19.944773Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"f1 = 0.836066000363923, accuracy = 0.851782363977486\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(0.836066000363923, 0.851782363977486)"},"metadata":{}}]},{"cell_type":"markdown","source":"**3rd Category: Paragraph data**","metadata":{}},{"cell_type":"code","source":"paragraph_df = test_df[test_df['string'].apply(lambda x: len(nltk.sent_tokenize(x)) > 1)]\nX_test = paragraph_df['string']\ny_test = label_encoder.transform(paragraph_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:04:27.057563Z","iopub.execute_input":"2024-04-14T10:04:27.058549Z","iopub.status.idle":"2024-04-14T10:04:31.097213Z","shell.execute_reply.started":"2024-04-14T10:04:27.058514Z","shell.execute_reply":"2024-04-14T10:04:31.096239Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"f1 = 0.8511515645777811, accuracy = 0.8595641646489104\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(0.8511515645777811, 0.8595641646489104)"},"metadata":{}}]},{"cell_type":"markdown","source":"**4th Category: Typo data**","metadata":{}},{"cell_type":"code","source":"import random\ndef rearrange_letter(word):\n    word_list = list(word)\n    n = len(word_list)\n    if n == 1:\n        return ''.join(word_list)\n    \n    idx = random.randint(0, n - 2)\n    word_list[idx], word_list[idx + 1] = word_list[idx + 1], word_list[idx]\n    return ''.join(word_list)\n\ndef rearrange_word(text):\n    words = nltk.word_tokenize(text)\n    num_words = len(words)\n\n    # rearrange letter for some random word\n    for _ in range(5):\n        idx = random.randint(0, num_words - 1)\n        words[idx] = rearrange_letter(words[idx])\n    \n    # rearrange word\n    for _ in range(min(3, num_words - 1)):\n        idx = random.randint(0, num_words - 2)\n        words[idx], words[idx + 1] = words[idx + 1], words[idx]\n\n    return ' '.join(words)\n\ntypo_series = test_df['string'].apply(rearrange_word)\n\ntypo_df = pd.DataFrame({\n    'label': test_df.label,\n    'string': typo_series\n})\nX_test = typo_df['string']\ny_test = label_encoder.transform(typo_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:04:51.308869Z","iopub.execute_input":"2024-04-14T10:04:51.309600Z","iopub.status.idle":"2024-04-14T10:05:09.559442Z","shell.execute_reply.started":"2024-04-14T10:04:51.309564Z","shell.execute_reply":"2024-04-14T10:05:09.558531Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"f1 = 0.8006081768309743, accuracy = 0.8275120902740463\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(0.8006081768309743, 0.8275120902740463)"},"metadata":{}}]},{"cell_type":"markdown","source":"**5th Category: Synonym data**","metadata":{}},{"cell_type":"code","source":"synonymized_test_df = pd.read_json('/kaggle/input/scicite2/synonymized.jsonl', lines=True)\nX_test = synonymized_test_df['string']\ny_test = label_encoder.transform(synonymized_test_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:05:30.633400Z","iopub.execute_input":"2024-04-14T10:05:30.633946Z","iopub.status.idle":"2024-04-14T10:05:48.080349Z","shell.execute_reply.started":"2024-04-14T10:05:30.633915Z","shell.execute_reply":"2024-04-14T10:05:48.079487Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"f1 = 0.7087132710001441, accuracy = 0.7807630306286942\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(0.7087132710001441, 0.7807630306286942)"},"metadata":{}}]},{"cell_type":"markdown","source":"**6th Category: Paraphrased data**","metadata":{}},{"cell_type":"code","source":"paraphrased_test_df = pd.read_json('/kaggle/input/scicite2/paraphrased.jsonl', lines=True)\nX_test = paraphrased_test_df['string']\ny_test = label_encoder.transform(paraphrased_test_df['label'])\neval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T10:05:58.768665Z","iopub.execute_input":"2024-04-14T10:05:58.769556Z","iopub.status.idle":"2024-04-14T10:06:16.329602Z","shell.execute_reply.started":"2024-04-14T10:05:58.769524Z","shell.execute_reply":"2024-04-14T10:06:16.328628Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"f1 = 0.804372514705901, accuracy = 0.8216012896292316\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(0.804372514705901, 0.8216012896292316)"},"metadata":{}}]}]}