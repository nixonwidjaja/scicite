{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8038802,"sourceType":"datasetVersion","datasetId":4739305}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-10T13:46:40.184862Z","iopub.execute_input":"2024-04-10T13:46:40.185455Z","iopub.status.idle":"2024-04-10T13:46:41.110763Z","shell.execute_reply.started":"2024-04-10T13:46:40.185423Z","shell.execute_reply":"2024-04-10T13:46:41.109849Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/scicite/test.jsonl\n/kaggle/input/scicite/train.jsonl\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_json('/kaggle/input/scicite/train.jsonl', lines=True)\nX_train = train_df['string']\ny_train = train_df['label']\n\ntest_df = pd.read_json('/kaggle/input/scicite/test.jsonl', lines=True)\nX_test = test_df['string']\ny_test = test_df['label']\n\nprint(train_df.shape, test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:41.112375Z","iopub.execute_input":"2024-04-10T13:46:41.112752Z","iopub.status.idle":"2024-04-10T13:46:41.371114Z","shell.execute_reply.started":"2024-04-10T13:46:41.112727Z","shell.execute_reply":"2024-04-10T13:46:41.370155Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(8243, 15) (1861, 14)\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:41.372380Z","iopub.execute_input":"2024-04-10T13:46:41.372743Z","iopub.status.idle":"2024-04-10T13:46:41.377361Z","shell.execute_reply.started":"2024-04-10T13:46:41.372711Z","shell.execute_reply":"2024-04-10T13:46:41.376506Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch \nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom torch.optim import Adam\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.utils import resample\n\ndef augment_data_multiclass(X, y):\n    df = pd.concat([X, y], axis=1)\n    majority_class_size = df['label'].value_counts().max()\n    upsampled_dataframes = []\n    for class_label in df['label'].unique():\n        class_df = df[df['label'] == class_label]\n        if len(class_df) < majority_class_size:\n            class_df_upsampled = resample(class_df, replace=True, n_samples=majority_class_size, random_state=10)\n            upsampled_dataframes.append(class_df_upsampled)\n        else:\n            upsampled_dataframes.append(class_df)\n    upsampled_df = pd.concat(upsampled_dataframes)\n    return upsampled_df['string'], upsampled_df['label']\n\n# train the model for a given number of epochs\ndef train_model(model, tokenizer, num_epoch, learning_rate, batch_size, X_train, y_train):\n    # Encode the training data\n    encoded_data_train = tokenizer.batch_encode_plus(\n        X_train,\n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n    labels_train = torch.tensor(y_train)\n\n    # Create data loader for training\n    dataset_train = TensorDataset(encoded_data_train['input_ids'], encoded_data_train['attention_mask'], labels_train)\n    dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size)\n\n    # Connect to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    # Define optimizer for training data\n    optimizer = Adam(model.parameters(), lr=learning_rate)\n\n    # Training loop\n    for epoch in range(num_epoch):\n        model.train()\n\n        curr_total_loss = 0.\n        count = 0\n        \n        for train_batch in dataloader_train:\n            optimizer.zero_grad()\n\n            id, mask, label = train_batch\n            id = id.to(device)\n            mask = mask.to(device)\n            label = label.to(device)\n\n            outputs = model(id, attention_mask=mask, labels=label)\n\n            loss = outputs.loss\n\n            curr_total_loss += loss.item()\n            count += 1\n\n            loss.backward()\n            \n            optimizer.step()\n\n        avg_loss = curr_total_loss / count\n        print(epoch, avg_loss)       \n    \n    return model \n\n# return f1 macro and accuracy of the model\ndef eval_model(model, tokenizer, X_test, y_test):\n    encoded_data_test = tokenizer.batch_encode_plus(\n        X_test,\n        add_special_tokens=True, \n        return_attention_mask=True, \n        pad_to_max_length=True, \n        max_length=512, \n        return_tensors='pt'\n    )\n    labels_test = torch.tensor(y_test)\n\n    # Create data loader for test data\n    batch_size = 16\n    test_dataset = TensorDataset(encoded_data_test['input_ids'], encoded_data_test['attention_mask'], labels_test)\n    test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n\n    # Connect to GPU if available\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model.to(device)\n\n    # Evaluate the model\n    model.eval()\n    predictions = []\n    labels = []\n    with torch.no_grad():\n        for test_batch in test_dataloader:\n            id, mask, label = test_batch\n            id = id.to(device)\n            mask = mask.to(device)\n            label = label.to(device)\n\n            outputs = model(id, attention_mask=mask, labels=label)\n            logits = outputs.logits\n            _, prediction  = torch.max(logits, dim=1)\n\n            predictions.extend(prediction.tolist())\n            labels.extend(label.tolist())\n            \n    f1 = f1_score(labels, predictions, average='macro')\n    acc = accuracy_score(labels, predictions)\n    print(f\"f1 = {f1}, accuracy = {acc}\")\n    return f1, acc\n\n\ndef save_model(model, save_path):\n    torch.save(model.state_dict(), save_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:41.379280Z","iopub.execute_input":"2024-04-10T13:46:41.379554Z","iopub.status.idle":"2024-04-10T13:46:46.110909Z","shell.execute_reply.started":"2024-04-10T13:46:41.379532Z","shell.execute_reply":"2024-04-10T13:46:46.110032Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X_train, y_train = augment_data_multiclass(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:46.112136Z","iopub.execute_input":"2024-04-10T13:46:46.112587Z","iopub.status.idle":"2024-04-10T13:46:46.139437Z","shell.execute_reply.started":"2024-04-10T13:46:46.112559Z","shell.execute_reply":"2024-04-10T13:46:46.138634Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# Initialize LabelEncoder\nlabel_encoder = LabelEncoder()\n\n# Fit label encoder and transform string column\ny_train = label_encoder.fit_transform(y_train)\ny_test = label_encoder.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:46.140651Z","iopub.execute_input":"2024-04-10T13:46:46.140945Z","iopub.status.idle":"2024-04-10T13:46:46.151643Z","shell.execute_reply.started":"2024-04-10T13:46:46.140918Z","shell.execute_reply":"2024-04-10T13:46:46.150685Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\nmodel_name = 'distilbert-base-uncased'\ntokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\nmodel = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3)\nmodel = train_model(model, tokenizer, 1, 4e-5, 16, X_train.to_list(), y_train)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:46:46.152763Z","iopub.execute_input":"2024-04-10T13:46:46.153035Z","iopub.status.idle":"2024-04-10T13:53:20.631180Z","shell.execute_reply.started":"2024-04-10T13:46:46.153012Z","shell.execute_reply":"2024-04-10T13:53:20.630211Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a1f94c45ebe445aacfcd5addecb4448"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2b2b61496fb4f12bff130bb541c6a7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb6a13a9e4104bf9b7bf43d6b32ba7c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1bb26ebc4264f478383c0e2737c371c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19f4127b8d9a4941a2fd2fd95d73e778"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"0 0.3470238882121076\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_model(model, tokenizer, X_test.to_list(), y_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T13:53:56.571348Z","iopub.execute_input":"2024-04-10T13:53:56.572060Z","iopub.status.idle":"2024-04-10T13:54:13.609611Z","shell.execute_reply.started":"2024-04-10T13:53:56.572027Z","shell.execute_reply":"2024-04-10T13:54:13.608630Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"f1 = 0.8228689123127193, accuracy = 0.8404083825900054\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(0.8228689123127193, 0.8404083825900054)"},"metadata":{}}]}]}