{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farrelsalim/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/farrelsalim/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "from utils import eval_model, train_model, augment_data_multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>citeEnd</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>citeStart</th>\n",
       "      <th>string</th>\n",
       "      <th>label</th>\n",
       "      <th>label_confidence</th>\n",
       "      <th>citingPaperId</th>\n",
       "      <th>citedPaperId</th>\n",
       "      <th>isKeyCitation</th>\n",
       "      <th>id</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>excerpt_index</th>\n",
       "      <th>label2</th>\n",
       "      <th>label2_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explicit</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>168.0</td>\n",
       "      <td>However, how frataxin interacts with the Fe-S ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649</td>\n",
       "      <td>894be9b4ea46a5c422e81ef3c241072d4c73fdc0</td>\n",
       "      <td>True</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>1872080baa7d30ec8fb87be9a65358cd3a7fb649&gt;894be...</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>explicit</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Novel Quantitative Trait Loci for Seminal Root...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>In the study by Hickey et al. (2012), spikes w...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b</td>\n",
       "      <td>b6642e19efb8db5623b3cc4eef1c5822a6151107</td>\n",
       "      <td>True</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b&gt;b6642...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>explicit</td>\n",
       "      <td>228.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>225.0</td>\n",
       "      <td>The drug also reduces catecholamine secretion,...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc</td>\n",
       "      <td>4e6a17fb8d7a3cada601d942e22eb5da6d01adbd</td>\n",
       "      <td>False</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>9cdf605beb1aa1078f235c4332b3024daa8b31dc&gt;4e6a1...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>explicit</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>46.0</td>\n",
       "      <td>By clustering with lowly aggressive close kin ...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b</td>\n",
       "      <td>2cc6ff899bf17666ad35893524a4d61624555ed7</td>\n",
       "      <td>False</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>d9f3207db0c79a3b154f3875c9760cc6b056904b&gt;2cc6f...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explicit</td>\n",
       "      <td>239.0</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>234.0</td>\n",
       "      <td>Ophthalmic symptoms are rare manifestations of...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175</td>\n",
       "      <td>a5bb0ff1a026944d2a47a155462959af2b8505a8</td>\n",
       "      <td>False</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>88b86556857f4374842d2af2e359576806239175&gt;a5bb0...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>explicit</td>\n",
       "      <td>50.0</td>\n",
       "      <td></td>\n",
       "      <td>28.0</td>\n",
       "      <td>Importantly, the results of Pascalis et al. (2...</td>\n",
       "      <td>background</td>\n",
       "      <td>0.7350</td>\n",
       "      <td>6f68ccd37718366c40ae6aeedf0b935bf560b215</td>\n",
       "      <td>60ed4bdabf92b2fbd6162dbd8979888cccca55d7</td>\n",
       "      <td>True</td>\n",
       "      <td>6f68ccd37718366c40ae6aeedf0b935bf560b215&gt;60ed4...</td>\n",
       "      <td>6f68ccd37718366c40ae6aeedf0b935bf560b215&gt;60ed4...</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8239</th>\n",
       "      <td>explicit</td>\n",
       "      <td>182.0</td>\n",
       "      <td>DISCUSSION</td>\n",
       "      <td>179.0</td>\n",
       "      <td>As suggested by Nguena et al, there is a need ...</td>\n",
       "      <td>background</td>\n",
       "      <td>0.7508</td>\n",
       "      <td>f2a1c1704f9587c94ed95bc98179dc499e933f5e</td>\n",
       "      <td>574e659da7f6c62c07bfaaacd1f31d65bd75524c</td>\n",
       "      <td>True</td>\n",
       "      <td>f2a1c1704f9587c94ed95bc98179dc499e933f5e&gt;574e6...</td>\n",
       "      <td>f2a1c1704f9587c94ed95bc98179dc499e933f5e&gt;574e6...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8240</th>\n",
       "      <td>explicit</td>\n",
       "      <td>120.0</td>\n",
       "      <td>DISCUSSION</td>\n",
       "      <td>108.0</td>\n",
       "      <td>Skeletal muscle is also a primary site of dise...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>18c97ea2ff60c110cc2a523e0fdf729608cbb083</td>\n",
       "      <td>fc13b9c3dfcc121013edaa12fa8ce7842aaed21a</td>\n",
       "      <td>False</td>\n",
       "      <td>18c97ea2ff60c110cc2a523e0fdf729608cbb083&gt;fc13b...</td>\n",
       "      <td>18c97ea2ff60c110cc2a523e0fdf729608cbb083&gt;fc13b...</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8241</th>\n",
       "      <td>explicit</td>\n",
       "      <td>221.0</td>\n",
       "      <td></td>\n",
       "      <td>185.0</td>\n",
       "      <td>ACTIVATION OF TRANSCRIPTION FACTORS Roles for ...</td>\n",
       "      <td>method</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4ec9b89857c0b27e8a4bd3745b7358f387773527</td>\n",
       "      <td>81affdba19e38e2b17cf7b9e93792cc2028cf21d</td>\n",
       "      <td>True</td>\n",
       "      <td>4ec9b89857c0b27e8a4bd3745b7358f387773527&gt;81aff...</td>\n",
       "      <td>4ec9b89857c0b27e8a4bd3745b7358f387773527&gt;81aff...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8242</th>\n",
       "      <td>explicit</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Most studies focused on the relation between b...</td>\n",
       "      <td>background</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>42c954cad0de68657d4429b512d8fe75dceef13c</td>\n",
       "      <td>00afbfb391f7c15a73a4257b2c0fcd9767ece6a8</td>\n",
       "      <td>True</td>\n",
       "      <td>42c954cad0de68657d4429b512d8fe75dceef13c&gt;00afb...</td>\n",
       "      <td>42c954cad0de68657d4429b512d8fe75dceef13c&gt;00afb...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8243 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        source  citeEnd                                        sectionName  \\\n",
       "0     explicit    175.0                                       Introduction   \n",
       "1     explicit     36.0  Novel Quantitative Trait Loci for Seminal Root...   \n",
       "2     explicit    228.0                                       Introduction   \n",
       "3     explicit    110.0                                         Discussion   \n",
       "4     explicit    239.0                                         Discussion   \n",
       "...        ...      ...                                                ...   \n",
       "8238  explicit     50.0                                                      \n",
       "8239  explicit    182.0                                         DISCUSSION   \n",
       "8240  explicit    120.0                                         DISCUSSION   \n",
       "8241  explicit    221.0                                                      \n",
       "8242  explicit    102.0                                       Introduction   \n",
       "\n",
       "      citeStart                                             string  \\\n",
       "0         168.0  However, how frataxin interacts with the Fe-S ...   \n",
       "1          16.0  In the study by Hickey et al. (2012), spikes w...   \n",
       "2         225.0  The drug also reduces catecholamine secretion,...   \n",
       "3          46.0  By clustering with lowly aggressive close kin ...   \n",
       "4         234.0  Ophthalmic symptoms are rare manifestations of...   \n",
       "...         ...                                                ...   \n",
       "8238       28.0  Importantly, the results of Pascalis et al. (2...   \n",
       "8239      179.0  As suggested by Nguena et al, there is a need ...   \n",
       "8240      108.0  Skeletal muscle is also a primary site of dise...   \n",
       "8241      185.0  ACTIVATION OF TRANSCRIPTION FACTORS Roles for ...   \n",
       "8242       82.0  Most studies focused on the relation between b...   \n",
       "\n",
       "           label  label_confidence                             citingPaperId  \\\n",
       "0     background            1.0000  1872080baa7d30ec8fb87be9a65358cd3a7fb649   \n",
       "1     background            1.0000  ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b   \n",
       "2     background            1.0000  9cdf605beb1aa1078f235c4332b3024daa8b31dc   \n",
       "3     background            1.0000  d9f3207db0c79a3b154f3875c9760cc6b056904b   \n",
       "4     background            1.0000  88b86556857f4374842d2af2e359576806239175   \n",
       "...          ...               ...                                       ...   \n",
       "8238  background            0.7350  6f68ccd37718366c40ae6aeedf0b935bf560b215   \n",
       "8239  background            0.7508  f2a1c1704f9587c94ed95bc98179dc499e933f5e   \n",
       "8240  background            1.0000  18c97ea2ff60c110cc2a523e0fdf729608cbb083   \n",
       "8241      method               NaN  4ec9b89857c0b27e8a4bd3745b7358f387773527   \n",
       "8242  background            1.0000  42c954cad0de68657d4429b512d8fe75dceef13c   \n",
       "\n",
       "                                  citedPaperId  isKeyCitation  \\\n",
       "0     894be9b4ea46a5c422e81ef3c241072d4c73fdc0           True   \n",
       "1     b6642e19efb8db5623b3cc4eef1c5822a6151107           True   \n",
       "2     4e6a17fb8d7a3cada601d942e22eb5da6d01adbd          False   \n",
       "3     2cc6ff899bf17666ad35893524a4d61624555ed7          False   \n",
       "4     a5bb0ff1a026944d2a47a155462959af2b8505a8          False   \n",
       "...                                        ...            ...   \n",
       "8238  60ed4bdabf92b2fbd6162dbd8979888cccca55d7           True   \n",
       "8239  574e659da7f6c62c07bfaaacd1f31d65bd75524c           True   \n",
       "8240  fc13b9c3dfcc121013edaa12fa8ce7842aaed21a          False   \n",
       "8241  81affdba19e38e2b17cf7b9e93792cc2028cf21d           True   \n",
       "8242  00afbfb391f7c15a73a4257b2c0fcd9767ece6a8           True   \n",
       "\n",
       "                                                     id  \\\n",
       "0     1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...   \n",
       "1     ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...   \n",
       "2     9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...   \n",
       "3     d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...   \n",
       "4     88b86556857f4374842d2af2e359576806239175>a5bb0...   \n",
       "...                                                 ...   \n",
       "8238  6f68ccd37718366c40ae6aeedf0b935bf560b215>60ed4...   \n",
       "8239  f2a1c1704f9587c94ed95bc98179dc499e933f5e>574e6...   \n",
       "8240  18c97ea2ff60c110cc2a523e0fdf729608cbb083>fc13b...   \n",
       "8241  4ec9b89857c0b27e8a4bd3745b7358f387773527>81aff...   \n",
       "8242  42c954cad0de68657d4429b512d8fe75dceef13c>00afb...   \n",
       "\n",
       "                                              unique_id  excerpt_index label2  \\\n",
       "0     1872080baa7d30ec8fb87be9a65358cd3a7fb649>894be...             11    NaN   \n",
       "1     ce1d09a4a3a8d7fd3405b9328f65f00c952cf64b>b6642...              2    NaN   \n",
       "2     9cdf605beb1aa1078f235c4332b3024daa8b31dc>4e6a1...              0    NaN   \n",
       "3     d9f3207db0c79a3b154f3875c9760cc6b056904b>2cc6f...              3    NaN   \n",
       "4     88b86556857f4374842d2af2e359576806239175>a5bb0...              2    NaN   \n",
       "...                                                 ...            ...    ...   \n",
       "8238  6f68ccd37718366c40ae6aeedf0b935bf560b215>60ed4...             15    NaN   \n",
       "8239  f2a1c1704f9587c94ed95bc98179dc499e933f5e>574e6...              1    NaN   \n",
       "8240  18c97ea2ff60c110cc2a523e0fdf729608cbb083>fc13b...              8    NaN   \n",
       "8241  4ec9b89857c0b27e8a4bd3745b7358f387773527>81aff...              0    NaN   \n",
       "8242  42c954cad0de68657d4429b512d8fe75dceef13c>00afb...              0    NaN   \n",
       "\n",
       "      label2_confidence  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "8238                NaN  \n",
       "8239                NaN  \n",
       "8240                NaN  \n",
       "8241                NaN  \n",
       "8242                NaN  \n",
       "\n",
       "[8243 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_json('../train.jsonl', lines=True)\n",
    "X_train = train_df['string']\n",
    "y_train = train_df['label']\n",
    "\n",
    "dev_df = pd.read_json('../dev.jsonl', lines=True)\n",
    "X_dev = dev_df['string']\n",
    "y_dev = dev_df['label']\n",
    "\n",
    "test_df = pd.read_json('../test.jsonl', lines=True)\n",
    "X_test = test_df['string']\n",
    "y_test = test_df['label']\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_test.apply(lambda x: len(x)).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = augment_data_multiclass(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform string column\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_dev = label_encoder.transform(y_dev)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n",
      "score.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_model(model, tokenizer, 5, 4e-5, 16, X_train, y_train)\n",
    "# WARNING: This will take very long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First trained model \n",
    "\n",
    "This is GPT2 model with all parameters trained. Will take ~30 mins to train in SOC cluster.\n",
    "\n",
    "We use:\n",
    "- learning_rate = 4e-5\n",
    "- num_epoch = 1\n",
    "- batch_size = 16\n",
    "- tokenizer = default GPT2Tokenizer\n",
    "- Only data augmentation for preprocessing\n",
    "\n",
    "This can be trained by running `train_model(model, tokenizer, num_epoch=1, learning_rate=4e-5, batch_size=16, X_train, y_train, use_preprocess=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "# Unfortunately, can't push it to github as it exceeds the 100 MB limit\n",
    "# Ask the model from me if needed :)\n",
    "model.load_state_dict(torch.load('gpt2-1.pth'))\n",
    "\n",
    "# Alternatively, can do the following:\n",
    "# model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "# model = train_model(model, tokenizer, num_epoch=1, learning_rate=4e-5, batch_size=16, X_train, y_train, use_preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8506542868172478, 0.8602901665771091)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find evaluation in test data, we can get:\n",
    "# f1 = 0.8506542868172478 and accuracy = 0.8602901665771091\n",
    "# WARNING: this will take quite long without GPU\n",
    "eval_model(model, tokenizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trained model \n",
    "\n",
    "This is GPT2 model with all parameters trained. Will take ~6 hours to train in SOC cluster.\n",
    "\n",
    "We use:\n",
    "- learning_rate = 4e-5\n",
    "- num_epoch = 10\n",
    "- batch_size = 16\n",
    "- tokenizer = default GPT2Tokenizer\n",
    "- Only data augmentation for preprocessing\n",
    "\n",
    "This can be trained by running `train_model(model, tokenizer, num_epoch=10, learning_rate=4e-5, batch_size=16, X_train, y_train, use_preprocess=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "# Unfortunately, can't push it to github as it exceeds the 100 MB limit\n",
    "# Ask the model from me if needed :)\n",
    "model.load_state_dict(torch.load('gpt2-2.pth'))\n",
    "\n",
    "# Alternatively, can do the following:\n",
    "# model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "# model = train_model(model, tokenizer, num_epoch=10, learning_rate=4e-5, batch_size=16, X_train, y_train, use_preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find evaluation in test data, we can get:\n",
    "# f1 = 0.8382855666754353 and 0.8538420204191295\n",
    "# WARNING: this will take quite long without GPU\n",
    "eval_model(model, tokenizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third trained model \n",
    "\n",
    "This is GPT2 model with all parameters trained. Will take ~30 mins to train in SOC cluster.\n",
    "\n",
    "We use:\n",
    "- learning_rate = 2e-5\n",
    "- num_epoch = 1\n",
    "- batch_size = 16\n",
    "- tokenizer = default GPT2Tokenizer\n",
    "- Only data augmentation for preprocessing\n",
    "\n",
    "This can be trained by running `train_model(model, tokenizer, num_epoch=1, learning_rate=2e-5, batch_size=16, X_train, y_train, use_preprocess=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "# Unfortunately, can't push it to github as it exceeds the 100 MB limit\n",
    "# Ask the model from me if needed :)\n",
    "model.load_state_dict(torch.load('gpt2-3.pth'))\n",
    "\n",
    "# Alternatively, can do the following:\n",
    "# model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "# model = train_model(model, tokenizer, num_epoch=1, learning_rate=2e-5, batch_size=16, X_train, y_train, use_preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find evaluation in test data, we can get:\n",
    "# f1 = 0.8170804618955835 and accuracy = 0.8350349274583557\n",
    "# WARNING: this will take quite long without GPU\n",
    "eval_model(model, tokenizer, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth trained model \n",
    "\n",
    "This is GPT2 model with all parameters trained. Will take ~6 hours to train in SOC cluster.\n",
    "\n",
    "We use:\n",
    "- learning_rate = 2e-5\n",
    "- num_epoch = 10\n",
    "- batch_size = 16\n",
    "- tokenizer = default GPT2Tokenizer\n",
    "- Only data augmentation for preprocessing\n",
    "\n",
    "This can be trained by running `train_model(model, tokenizer, num_epoch=1, learning_rate=2e-5, batch_size=16, X_train, y_train, use_preprocess=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load previously trained model\n",
    "# Unfortunately, can't push it to github as it exceeds the 100 MB limit\n",
    "# Ask the model from me if needed :)\n",
    "model.load_state_dict(torch.load('gpt2-4.pth'))\n",
    "\n",
    "# Alternatively, can do the following:\n",
    "# model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "# model.config.pad_token_id = model.config.eos_token_id\n",
    "# model = train_model(model, tokenizer, num_epoch=10, learning_rate=2e-5, batch_size=16, X_train, y_train, use_preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8432042425451008, 0.8592154755507792)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find evaluation in test data, we can get:\n",
    "# f1 = 0.8432042425451008 and accuracy 0.8592154755507792\n",
    "# WARNING: this will take quite long without GPU\n",
    "eval_model(model, tokenizer, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
